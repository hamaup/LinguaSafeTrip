"""
é©å¿œçš„ç½å®³ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚µãƒ¼ãƒ“ã‚¹
å¹³å¸¸æ™‚: ç½å®³äºˆé˜²ãƒ»ä¸€èˆ¬çš„ç½å®³ãƒ‹ãƒ¥ãƒ¼ã‚¹
ç·Šæ€¥æ™‚: è¢«ç½åœ°ã®æœ€æ–°ç½å®³æƒ…å ±ï¼ˆä½ç½®ç‰¹åŒ–å‹ï¼‰
"""

import asyncio
import logging
import json
import os
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Any, Set
from dataclasses import dataclass
from enum import Enum

from app.tools.web_search_tools import get_web_search_tool
from app.collectors.official_news_collector import collect_official_news_periodically
from app.schemas.common.location import Location
from app.utils.geo_utils import get_location_string
from app.db.firestore_client import get_db
# Mock news manager removed - using web_news_cache_manager instead
from app.services.web_news_cache_manager import web_news_cache_manager
from app.config import app_settings

logger = logging.getLogger(__name__)

class CollectionMode(str, Enum):
    """åé›†ãƒ¢ãƒ¼ãƒ‰"""
    NORMAL = "normal"      # å¹³å¸¸æ™‚
    EMERGENCY = "emergency" # ç·Šæ€¥æ™‚

@dataclass
class NewsCollectionConfig:
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†è¨­å®š"""
    mode: CollectionMode
    interval_minutes: int
    max_articles_per_cycle: int
    search_keywords: List[str]
    trusted_sources: List[str]
    location_specific: bool = False
    target_location: Optional[Location] = None

@dataclass
class CollectedNews:
    """åé›†ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹"""
    article_id: str
    title: str
    content: str
    url: str
    source: str
    published_at: datetime
    collected_at: datetime
    mode: CollectionMode
    location: Optional[Location] = None
    relevance_score: float = 0.0
    urgency_level: str = "normal"  # normal, high, critical, emergency
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "article_id": self.article_id,
            "title": self.title,
            "content": self.content,
            "url": self.url,
            "source": self.source,
            "published_at": self.published_at.isoformat(),
            "collected_at": self.collected_at.isoformat(),
            "mode": self.mode,
            "location": {
                "latitude": self.location.latitude,
                "longitude": self.location.longitude
            } if self.location else None,
            "relevance_score": self.relevance_score,
            "urgency_level": self.urgency_level
        }

class AdaptiveNewsCollector:
    """é©å¿œçš„ç½å®³ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.web_search_tool = get_web_search_tool()
        self.current_mode = CollectionMode.NORMAL
        self.is_running = False
        self._collector_task: Optional[asyncio.Task] = None
        
        # ç’°å¢ƒè¨­å®š
        self.environment = os.getenv("ENVIRONMENT", "production").lower()
        
        # .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é–“éš”è¨­å®šã‚’å–å¾—
        normal_interval = int(os.getenv("NEWS_COLLECTION_NORMAL_INTERVAL_MINUTES", "60"))
        emergency_interval = int(os.getenv("NEWS_COLLECTION_EMERGENCY_INTERVAL_MINUTES", "2"))
        
        # åé›†è¨­å®š
        self.normal_config = NewsCollectionConfig(
            mode=CollectionMode.NORMAL,
            interval_minutes=normal_interval,
            max_articles_per_cycle=10,
            search_keywords=[
                "ç½å®³å¯¾ç­–", "é˜²ç½", "å‚™è“„", "é¿é›£è¨“ç·´", "åœ°éœ‡å¯¾ç­–",
                "å°é¢¨å¯¾ç­–", "æ´ªæ°´å¯¾ç­–", "ç«ç½äºˆé˜²", "æ•‘æ€¥æ³•",
                "é˜²ç½ã‚°ãƒƒã‚º", "éå¸¸é£Ÿ", "ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—"
            ],
            trusted_sources=[
                "bousai.go.jp",      # å†…é–£åºœé˜²ç½
                "fdma.go.jp",        # æ¶ˆé˜²åº
                "jma.go.jp",         # æ°—è±¡åº
                "nhk.or.jp",         # NHK
                "asahi.com",         # æœæ—¥æ–°è
                "mainichi.jp",       # æ¯æ—¥æ–°è
                "yomiuri.co.jp",     # èª­å£²æ–°è
                "nikkei.com"         # æ—¥çµŒæ–°è
            ]
        )
        
        self.emergency_config = NewsCollectionConfig(
            mode=CollectionMode.EMERGENCY,
            interval_minutes=emergency_interval,
            max_articles_per_cycle=20,
            search_keywords=[
                "åœ°éœ‡é€Ÿå ±", "æ´¥æ³¢è­¦å ±", "é¿é›£æŒ‡ç¤º", "ç·Šæ€¥äº‹æ…‹",
                "è¢«å®³çŠ¶æ³", "é“è·¯çŠ¶æ³", "äº¤é€šæƒ…å ±", "é¿é›£æ‰€",
                "åœé›»", "æ–­æ°´", "ãƒ©ã‚¤ãƒ•ãƒ©ã‚¤ãƒ³", "æ•‘æ´",
                "å®‰å¦ç¢ºèª", "ç½å®³å¯¾ç­–æœ¬éƒ¨"
            ],
            trusted_sources=[
                "jma.go.jp",         # æ°—è±¡åºï¼ˆæœ€å„ªå…ˆï¼‰
                "bousai.go.jp",      # å†…é–£åºœé˜²ç½
                "nhk.or.jp",         # NHK
                "yahoo.co.jp",       # Yahoo!é˜²ç½é€Ÿå ±
                "weathernews.jp",    # ã‚¦ã‚§ã‚¶ãƒ¼ãƒ‹ãƒ¥ãƒ¼ã‚¹
                "fdma.go.jp",        # æ¶ˆé˜²åº
                "kantei.go.jp",      # é¦–ç›¸å®˜é‚¸
                "cao.go.jp"          # å†…é–£åºœ
            ],
            location_specific=True
        )
        
        # åé›†ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.collected_news: Dict[str, CollectedNews] = {}
        self.emergency_locations: Set[str] = set()  # ç·Šæ€¥ç›£è¦–ä¸­ã®ä½ç½®ï¼ˆç·¯åº¦çµŒåº¦ã®ãƒãƒƒã‚·ãƒ¥ï¼‰
        
        if logger.isEnabledFor(logging.DEBUG):
            logger.debug(f"Adaptive News Collector initialized - Environment: {self.environment}, "
                       f"Normal interval: {normal_interval}min, Emergency interval: {emergency_interval}min")

    async def start_collection(self):
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚’é–‹å§‹"""
        if self.is_running:
            logger.warning("Adaptive news collection is already running")
            return
        
        self.is_running = True
        self._collector_task = asyncio.create_task(self._collection_loop())
        
        if logger.isEnabledFor(logging.DEBUG):
            pass
    async def stop_collection(self):
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚’åœæ­¢"""
        self.is_running = False
        
        if self._collector_task:
            self._collector_task.cancel()
            try:
                await self._collector_task
            except asyncio.CancelledError:
                pass
        
        if logger.isEnabledFor(logging.DEBUG):
            pass
    def switch_to_emergency_mode(self, emergency_location: Location):
        """ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ"""
        self.current_mode = CollectionMode.EMERGENCY
        self.emergency_config.target_location = emergency_location
        
        # ç·Šæ€¥ä½ç½®ã‚’è¨˜éŒ²
        location_hash = f"{emergency_location.latitude:.4f}_{emergency_location.longitude:.4f}"
        self.emergency_locations.add(location_hash)
        
        if logger.isEnabledFor(logging.DEBUG):
            pass
        else:
            logger.warning(f"ğŸš¨ Switched to EMERGENCY mode for location: {get_location_string(emergency_location)}")

    def switch_to_normal_mode(self):
        """å¹³å¸¸ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ"""
        self.current_mode = CollectionMode.NORMAL
        self.emergency_locations.clear()
        
        if logger.isEnabledFor(logging.DEBUG):
            pass
    async def add_emergency_location(self, location: Location):
        """ç·Šæ€¥ç›£è¦–ä½ç½®ã‚’è¿½åŠ """
        location_hash = f"{location.latitude:.4f}_{location.longitude:.4f}"
        self.emergency_locations.add(location_hash)
        
        if self.current_mode == CollectionMode.NORMAL:
            self.switch_to_emergency_mode(location)
        
        if logger.isEnabledFor(logging.DEBUG):
            pass
    
    async def remove_emergency_location(self, location: Location):
        """ç·Šæ€¥ç›£è¦–ä½ç½®ã‚’å‰Šé™¤"""
        location_hash = f"{location.latitude:.4f}_{location.longitude:.4f}"
        self.emergency_locations.discard(location_hash)
        
        # ç·Šæ€¥ä½ç½®ãŒãªããªã£ãŸã‚‰å¹³å¸¸ãƒ¢ãƒ¼ãƒ‰ã«æˆ»ã™
        if not self.emergency_locations and self.current_mode == CollectionMode.EMERGENCY:
            self.switch_to_normal_mode()
        
        if logger.isEnabledFor(logging.DEBUG):
            pass
    
    async def _collection_loop(self):
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ãƒ«ãƒ¼ãƒ—"""
        while self.is_running:
            try:
                current_config = self._get_current_config()
                await self._collect_news(current_config)
                
                # åé›†é–“éš”ã«å¿œã˜ã¦å¾…æ©Ÿ
                wait_seconds = current_config.interval_minutes * 60
                await asyncio.sleep(wait_seconds)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Error in news collection loop: {e}", exc_info=True)
                await asyncio.sleep(60)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1åˆ†å¾…æ©Ÿ

    def _get_current_config(self) -> NewsCollectionConfig:
        """ç¾åœ¨ã®è¨­å®šã‚’å–å¾—"""
        return self.emergency_config if self.current_mode == CollectionMode.EMERGENCY else self.normal_config

    async def _collect_news(self, config: NewsCollectionConfig):
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†"""
        try:
            if logger.isEnabledFor(logging.DEBUG):
                pass
            
            collected_articles = []
            
            if config.mode == CollectionMode.NORMAL:
                # å¹³å¸¸æ™‚: ä¸€èˆ¬çš„ãªç½å®³äºˆé˜²ãƒ‹ãƒ¥ãƒ¼ã‚¹
                collected_articles = await self._collect_general_disaster_news(config)
            else:
                # ç·Šæ€¥æ™‚: ä½ç½®ç‰¹åŒ–å‹ç½å®³æƒ…å ±
                collected_articles = await self._collect_emergency_disaster_info(config)
            
            # åé›†çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            new_articles_count = 0
            for article in collected_articles:
                if article.article_id not in self.collected_news:
                    new_articles_count += 1
                self.collected_news[article.article_id] = article
            
            # å¤ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å‰Šé™¤ï¼ˆ24æ™‚é–“ä»¥ä¸Šå¤ã„ï¼‰
            await self._cleanup_old_news()
            
            if logger.isEnabledFor(logging.DEBUG):
                pass
            # æ–°ã—ã„è¨˜äº‹ãŒè¿½åŠ ã•ã‚ŒãŸå ´åˆã€ãƒ•ãƒ©ã‚°ã‚’è¨­å®šï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãŒæ¬¡å›APIã‚³ãƒ¼ãƒ«æ™‚ã«ææ¡ˆç”Ÿæˆï¼‰
            if new_articles_count > 0:
                await self._mark_new_news_for_proactive_suggestions(collected_articles, config.mode)
            
        except Exception as e:
            logger.error(f"Error collecting news: {e}", exc_info=True)

    async def _collect_general_disaster_news(self, config: NewsCollectionConfig) -> List[CollectedNews]:
        """ä¸€èˆ¬çš„ãªç½å®³äºˆé˜²ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†"""
        articles = []
        
        try:
            # ç½å®³äºˆé˜²é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢
            for keyword in config.search_keywords[:3]:  # ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿
                search_query = f"{keyword} å¯¾ç­– æœ€æ–°"
                
                try:
                    results = await self.web_search_tool._arun(
                        query=search_query,
                        max_results=3
                    )
                    
                    for result in results:
                        article = await self._convert_to_news_article(result, config, keyword)
                        if article:
                            articles.append(article)
                
                except Exception as e:
                    logger.error(f"Search failed for keyword '{keyword}': {e}")
            
            # é‡è¤‡é™¤å»
            unique_articles = {}
            for article in articles:
                if article.url not in unique_articles:
                    unique_articles[article.url] = article
            
            return list(unique_articles.values())[:config.max_articles_per_cycle]
            
        except Exception as e:
            logger.error(f"Error collecting general disaster news: {e}")
            return []

    async def _collect_emergency_disaster_info(self, config: NewsCollectionConfig) -> List[CollectedNews]:
        """ç·Šæ€¥æ™‚ã®ä½ç½®ç‰¹åŒ–å‹ç½å®³æƒ…å ±ã‚’åé›†"""
        articles = []
        
        try:
            if not config.target_location:
                logger.warning("No target location set for emergency collection")
                return []
            
            location_str = get_location_string(config.target_location)
            
            # ä½ç½®ç‰¹åŒ–å‹ã®ç·Šæ€¥æƒ…å ±æ¤œç´¢
            for keyword in config.search_keywords[:5]:  # ã‚ˆã‚Šå¤šãã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
                search_query = f"{location_str} {keyword} é€Ÿå ± æœ€æ–°"
                
                try:
                    results = await self.web_search_tool._arun(
                        query=search_query,
                        max_results=5  # ç·Šæ€¥æ™‚ã¯ã‚ˆã‚Šå¤šãå–å¾—
                    )
                    
                    for result in results:
                        article = await self._convert_to_news_article(
                            result, config, keyword, config.target_location
                        )
                        if article:
                            # ç·Šæ€¥æ™‚ã¯é–¢é€£åº¦ã¨ç·Šæ€¥åº¦ã‚’è©•ä¾¡
                            article.relevance_score = await self._calculate_relevance_score(article, keyword)
                            article.urgency_level = self._determine_urgency_level(article)
                            articles.append(article)
                
                except Exception as e:
                    logger.error(f"Emergency search failed for keyword '{keyword}': {e}")
            
            # é–¢é€£åº¦ã§ã‚½ãƒ¼ãƒˆã—ã¦é‡è¤‡é™¤å»
            articles.sort(key=lambda x: x.relevance_score, reverse=True)
            unique_articles = {}
            for article in articles:
                if article.url not in unique_articles:
                    unique_articles[article.url] = article
            
            return list(unique_articles.values())[:config.max_articles_per_cycle]
            
        except Exception as e:
            logger.error(f"Error collecting emergency disaster info: {e}")
            return []

    async def _convert_to_news_article(
        self, 
        search_result: Dict[str, Any], 
        config: NewsCollectionConfig,
        keyword: str,
        location: Optional[Location] = None
    ) -> Optional[CollectedNews]:
        """æ¤œç´¢çµæœã‚’ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«å¤‰æ›"""
        try:
            title = search_result.get("title", "")
            content = search_result.get("snippet", "")
            url = search_result.get("link", "")
            source = search_result.get("source_domain", "")
            
            # ç½å®³é–¢é€£ã§ãªã„çµæœã‚’ãƒ•ã‚£ãƒ«ã‚¿
            if not await self._is_disaster_related(title + " " + content, config.mode):
                return None
            
            # è¨˜äº‹IDã‚’ç”Ÿæˆ
            import hashlib
            article_id = hashlib.md5(f"{url}_{datetime.now().strftime('%Y%m%d%H')}".encode()).hexdigest()[:12]
            
            article = CollectedNews(
                article_id=article_id,
                title=title,
                content=content,
                url=url,
                source=source,
                published_at=datetime.now(),  # å®Ÿéš›ã®å…¬é–‹æ—¥æ™‚ã¯å–å¾—å›°é›£ãªãŸã‚ç¾åœ¨æ™‚åˆ»
                collected_at=datetime.now(),
                mode=config.mode,
                location=location
            )
            
            return article
            
        except Exception as e:
            logger.error(f"Failed to convert search result to news article: {e}")
            return None

    async def _is_disaster_related(self, content: str, mode: CollectionMode) -> bool:
        """ç½å®³é–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã©ã†ã‹åˆ¤å®šï¼ˆLLMè‡ªç„¶è¨€èªç†è§£ã‚’ä½¿ç”¨ï¼‰"""
        try:
            from app.agents.safety_beacon_agent.core.llm_singleton import ainvoke_llm
            
            if mode == CollectionMode.NORMAL:
                mode_context = "disaster preparedness, safety planning, and general disaster information"
            else:
                mode_context = "emergency disaster response, damage reports, evacuation information, and immediate safety updates"
            
            prompt = f"""Determine if this content is related to {mode_context} using natural language understanding.

Content: {content[:300]}...

Is this content relevant to disaster safety and management in the current context?

Respond with only: YES or NO"""

            response = await ainvoke_llm(prompt, task_type="disaster_relevance", temperature=0.1)
            return response.strip().upper() == "YES"
            
        except Exception as e:
            logger.warning(f"LLM disaster relevance classification failed: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä¿å®ˆçš„åˆ¤å®šï¼ˆç½å®³é–¢é€£ã¨ä»®å®šï¼‰
            return True

    async def _calculate_relevance_score(self, article: CollectedNews, keyword: str) -> float:
        """é–¢é€£åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        score = 0.0
        content = (article.title + " " + article.content).lower()
        
        # LLMãƒ™ãƒ¼ã‚¹ã®é–¢é€£åº¦åˆ†æï¼ˆCLAUDE.mdåŸå‰‡ã«å¾“ã„è‡ªç„¶è¨€èªç†è§£ã‚’ä½¿ç”¨ï¼‰
        try:
            from app.agents.safety_beacon_agent.core.llm_singleton import ainvoke_llm
            
            # çŸ­ç¸®ç‰ˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§åˆ†æ
            short_content = content[:800]  # LLMåŠ¹ç‡åŒ–
            
            # ç°¡æ½”ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§é–¢é€£åº¦åˆ¤å®š
            prompt = f"""Rate disaster relevance (0.0-1.0) for: "{keyword}"
Article: {short_content}
Respond with number only (e.g. 0.7)"""

            import asyncio
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨
                raise Exception("Skip LLM in async context")
            
            response = await ainvoke_llm(prompt, task_type="relevance", temperature=0.3)
            llm_score = float(response.strip())
            score += max(0.0, min(0.6, llm_score))  # LLMã‚¹ã‚³ã‚¢ã‚’æœ€å¤§0.6ã«åˆ¶é™
            
        except Exception:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬åˆ¤å®šï¼ˆè‡ªç„¶è¨€èªç†è§£ãªã—ã®æš«å®šæªç½®ï¼‰
            if keyword.lower() in content:
                score += 0.3
        
        # ä¿¡é ¼ã§ãã‚‹ã‚½ãƒ¼ã‚¹
        trusted_domains = ["jma.go.jp", "nhk.or.jp", "bousai.go.jp"]
        if any(domain in article.source for domain in trusted_domains):
            score += 0.3
        
        return min(score, 1.0)

    async def _determine_urgency_level(self, article: CollectedNews) -> str:
        """ç·Šæ€¥åº¦ãƒ¬ãƒ™ãƒ«ã‚’åˆ¤å®šï¼ˆLLMè‡ªç„¶è¨€èªåˆ†é¡ã‚’ä½¿ç”¨ï¼‰"""
        try:
            from app.agents.safety_beacon_agent.core.llm_singleton import ainvoke_llm
            
            prompt = f"""Analyze the urgency level of this disaster news article using natural language understanding.

Article Title: {article.title}
Article Content: {article.content[:500]}...

Determine the urgency level based on the severity and immediacy of the disaster situation described:

- "emergency": Immediate life-threatening situations requiring urgent action
- "critical": Serious situations requiring prompt attention  
- "high": Important information that needs attention soon
- "normal": General information or updates

Consider the overall context and severity, not just specific keywords.

Respond with only one word: emergency, critical, high, or normal"""

            response = await ainvoke_llm(prompt, task_type="urgency_classification", temperature=0.2)
            level = response.strip().lower()
            
            if level in ["emergency", "critical", "high", "normal"]:
                return level
            else:
                return "normal"
                
        except Exception as e:
            logger.warning(f"LLM urgency classification failed: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ¤å®š
            return "normal"

    async def _cleanup_old_news(self):
        """å¤ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å‰Šé™¤"""
        current_time = datetime.now()
        expired_ids = []
        
        for article_id, article in self.collected_news.items():
            age_hours = (current_time - article.collected_at).total_seconds() / 3600
            if age_hours > 24:  # 24æ™‚é–“ä»¥ä¸Šå¤ã„
                expired_ids.append(article_id)
        
        for article_id in expired_ids:
            del self.collected_news[article_id]
        
        if expired_ids:
            pass
    async def _mark_new_news_for_proactive_suggestions(self, new_articles: List[CollectedNews], mode: CollectionMode):
        """æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå–å¾—ã•ã‚ŒãŸã“ã¨ã‚’ãƒãƒ¼ã‚¯ã—ã€æ¬¡å›ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ææ¡ˆã§ä½¿ç”¨å¯èƒ½ã«ã™ã‚‹"""
        try:
            # æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå–å¾—ã•ã‚ŒãŸæ™‚åˆ»ã‚’è¨˜éŒ²
            self.last_news_update = datetime.now()
            self.new_articles_count = len([
                article for article in new_articles
                if self._is_news_disaster_related(article)
            ])
            
            if logger.isEnabledFor(logging.DEBUG):
                pass
        except Exception as e:
            logger.error(f"Error marking new news for proactive suggestions: {e}")

    def _is_news_disaster_related(self, article: CollectedNews) -> bool:
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãŒç½å®³é–¢é€£ã‹ã©ã†ã‹LLMã§åˆ¤å®šï¼ˆCLAUDE.mdåŸå‰‡æº–æ‹ ï¼‰"""
        try:
            # åŠ¹ç‡åŒ–ã®ãŸã‚çŸ­ç¸®ç‰ˆã‚’ä½¿ç”¨
            content = f"{article.title} {article.content[:500]}"
            
            # ä¿¡é ¼ã§ãã‚‹ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®è¨˜äº‹ã¯ç½å®³é–¢é€£ã¨ã—ã¦æ‰±ã†ï¼ˆåŠ¹ç‡åŒ–ï¼‰
            trusted_domains = ["jma.go.jp", "nhk.or.jp", "bousai.go.jp", "fdma.go.jp"]
            if any(domain in article.source for domain in trusted_domains):
                return True
            
            # TODO: å°†æ¥çš„ã«ã¯LLMãƒ™ãƒ¼ã‚¹åˆ†é¡ã‚’å®Ÿè£…
            # ç¾åœ¨ã¯åŠ¹ç‡åŒ–ã®ãŸã‚åŸºæœ¬åˆ¤å®šã‚’ä½¿ç”¨ï¼ˆæš«å®šæªç½®ï¼‰
            disaster_indicators = [
                "ç½å®³", "é˜²ç½", "åœ°éœ‡", "æ´¥æ³¢", "å°é¢¨", "è­¦å ±", "é¿é›£", "ç·Šæ€¥"
            ]
            content_lower = content.lower()
            return any(indicator in content_lower for indicator in disaster_indicators)
        except:
            return False

    def has_new_news_for_suggestions(self) -> bool:
        """ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ææ¡ˆç”¨ã®æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        if not hasattr(self, 'last_news_update') or not hasattr(self, 'new_articles_count'):
            return False
        
        # éå»30åˆ†ä»¥å†…ã®æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚‹å ´åˆ
        if self.last_news_update and self.new_articles_count > 0:
            time_diff = (datetime.now() - self.last_news_update).total_seconds() / 60
            return time_diff <= 30  # 30åˆ†ä»¥å†…
        
        return False

    def get_new_news_info(self) -> Dict[str, Any]:
        """æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—"""
        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æ™‚ã¯Webæ¤œç´¢ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        if app_settings.is_test_mode():
            return self._get_web_cache_news_info()
        
        if not self.has_new_news_for_suggestions():
            return {}
        
        return {
            "new_articles_count": getattr(self, 'new_articles_count', 0),
            "last_update_time": getattr(self, 'last_news_update', None).isoformat() if hasattr(self, 'last_news_update') else None,
            "latest_articles": self.get_latest_news(mode=self.current_mode, limit=3)
        }
    
    def _get_web_cache_news_info(self) -> Dict[str, Any]:
        """Webæ¤œç´¢ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
        try:
            from app.config import app_settings
            
            news_type = "emergency" if self.current_mode == CollectionMode.EMERGENCY else "normal"
            cached_items = web_news_cache_manager.get_random_cached_news(news_type, count=5)
            
            # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰æ™‚ã®æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ¤å®šã«ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚’è¿½åŠ 
            if app_settings.is_test_mode():
                # æœ€å¾Œã®æ›´æ–°ã‹ã‚‰ååˆ†æ™‚é–“ãŒçµŒéã—ã¦ã„ã‚‹å ´åˆã®ã¿ã€Œæ–°ã—ã„ã€ã¨ã™ã‚‹
                now = datetime.now()
                if hasattr(self, 'last_news_update') and self.last_news_update:
                    time_since_last = (now - self.last_news_update).total_seconds()
                    cooldown_seconds = 30  # 30ç§’ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³
                    if time_since_last < cooldown_seconds:
                        # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ä¸­ã¯ã€Œæ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãªã—ã€
                        if logger.isEnabledFor(logging.DEBUG):
                            pass
                        self.new_articles_count = 0
                        return {
                            "new_articles_count": 0,
                            "has_new_articles": False,
                            "last_update_time": self.last_news_update.isoformat(),
                            "latest_articles": [],
                            "articles": []
                        }
                
                # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³å®Œäº†ã€æ›´æ–°æ™‚åˆ»ã‚’ãƒªã‚»ãƒƒãƒˆ
                self.last_news_update = now
                if logger.isEnabledFor(logging.DEBUG):
                    pass
            else:
                # æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰ã§ã¯å¾“æ¥é€šã‚Š
                self.last_news_update = datetime.now()
            
            if not cached_items:
                logger.warning(f"No cached {news_type} news found, using fallback")
                self.new_articles_count = 0  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã‚‚0ã«å¤‰æ›´
                return {
                    "new_articles_count": 0,
                    "last_update_time": datetime.now(timezone.utc).isoformat(),
                    "latest_articles": []
                }
            
            # CachedNewsItemã‚’CollectedNewsã«å¤‰æ›
            latest_articles = []
            for item in cached_items[:3]:
                article = CollectedNews(
                    article_id=f"web_cache_{item.search_query.replace(' ', '_')}_{int(datetime.now().timestamp())}",
                    title=item.title,
                    content=item.content,
                    url=item.url,
                    source=item.source,
                    published_at=datetime.fromisoformat(item.published_at.replace('Z', '+00:00')),
                    collected_at=datetime.fromisoformat(item.collected_at.replace('Z', '+00:00')),
                    mode=self.current_mode
                )
                latest_articles.append(article)
            
            # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ç”¨ã®å±æ€§è¨­å®š
            self.new_articles_count = len(cached_items)
            
            if logger.isEnabledFor(logging.DEBUG):
                pass
            return {
                "new_articles_count": len(cached_items),
                "last_update_time": datetime.now(timezone.utc).isoformat(),
                "latest_articles": latest_articles
            }
            
        except Exception as e:
            logger.error(f"Error getting web cache news info: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ç”¨ã®å±æ€§è¨­å®š
            self.new_articles_count = 0
            return {
                "new_articles_count": 0,
                "last_update_time": datetime.now(timezone.utc).isoformat(),
                "latest_articles": []
            }

    async def _trigger_proactive_suggestions_for_new_news(self, new_articles: List[CollectedNews], mode: CollectionMode):
        """æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒåé›†ã•ã‚ŒãŸéš›ã«æ—¢å­˜ã®ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ææ¡ˆã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã—ã¦ææ¡ˆã‚’é€ä¿¡"""
        try:
            if logger.isEnabledFor(logging.DEBUG):
                pass
            
            # å…¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒã‚¤ã‚¹ã‚’å–å¾—
            from app.crud.device_crud import get_all_devices
            devices = await get_all_devices()
            
            # FCMãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŒã¤ãƒ‡ãƒã‚¤ã‚¹ã®ã¿å¯¾è±¡
            active_devices = [
                device for device in devices
                if device.get("fcm_token") and device.get("is_active", True)
            ]
            
            if not active_devices:
                return
            
            if logger.isEnabledFor(logging.DEBUG):
                pass
            
            # æ—¢å­˜ã®ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ææ¡ˆã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
            from app.services.trigger_evaluator import TriggerEvaluator
            from app.agents.safety_beacon_agent.suggestion_generators.template_generator import SuggestionGenerator
            from app.schemas.agent.suggestions import DeviceContext, UserContext
            
            trigger_evaluator = TriggerEvaluator()
            suggestion_generator = SuggestionGenerator()
            
            # å„ãƒ‡ãƒã‚¤ã‚¹ã«å¯¾ã—ã¦ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ææ¡ˆã‚’ç”Ÿæˆãƒ»é€ä¿¡
            for device in active_devices[:10]:  # æœ€å¤§10ä»¶ã¾ã§ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼‰
                try:
                    await self._send_standard_proactive_suggestion(
                        device, new_articles, mode, trigger_evaluator, suggestion_generator
                    )
                except Exception as e:
                    logger.error(f"Failed to send proactive suggestion to device {device.get('device_id')}: {e}")
            
        except Exception as e:
            logger.error(f"Error triggering proactive suggestions: {e}")

    async def _send_standard_proactive_suggestion(
        self, 
        device: Dict[str, Any], 
        new_articles: List[CollectedNews], 
        mode: CollectionMode,
        trigger_evaluator,
        suggestion_generator
    ):
        """æ—¢å­˜ã®ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ææ¡ˆã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã—ã¦å€‹åˆ¥ãƒ‡ãƒã‚¤ã‚¹ã«ææ¡ˆã‚’é€ä¿¡"""
        try:
            device_id = device.get("device_id")
            fcm_token = device.get("fcm_token")
            language = device.get("language", "ja")
            
            # ãƒ‡ãƒã‚¤ã‚¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
            from app.schemas.agent.suggestions import DeviceContext, UserContext
            
            device_context = DeviceContext(
                device_id=device_id,
                platform=device.get("platform", "unknown"),
                battery_level=device.get("status", {}).get("battery_level"),
                is_charging=device.get("status", {}).get("is_charging", False),
                network_type=device.get("status", {}).get("network_type"),
                language=language
            )
            
            user_context = UserContext(
                user_id=device.get("user_id"),
                is_in_disaster_mode=(mode == CollectionMode.EMERGENCY),
                language=language,
                has_emergency_contacts=False,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                emergency_contacts_count=0,
                viewed_guides=[],
                last_quiz_date=None,
                last_active_date=None
            )
            
            # æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒªã‚¬ãƒ¼ã‚’è©•ä¾¡
            news_trigger_evaluation = await trigger_evaluator.evaluate_new_news_trigger(
                device_context, user_context, new_articles
            )
            
            if not news_trigger_evaluation:
                return
            
            # ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ææ¡ˆã‚’ç”Ÿæˆ
            suggestions = await suggestion_generator.generate_suggestions([news_trigger_evaluation])
            
            if not suggestions:
                return
            
            # æœ€åˆã®ææ¡ˆã‚’FCMã§é€ä¿¡
            suggestion = suggestions[0]
            await self._send_fcm_standard_notification(fcm_token, suggestion, language, new_articles)
            
            if logger.isEnabledFor(logging.DEBUG):
                pass
        except Exception as e:
            logger.error(f"Error sending standard proactive suggestion to device {device.get('device_id')}: {e}")

    async def _send_fcm_standard_notification(self, fcm_token: str, suggestion, language: str, new_articles: List[CollectedNews]):
        """æ¨™æº–çš„ãªãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ææ¡ˆã‚’FCMã§é€ä¿¡"""
        try:
            from app.utils.fcm_sender import send_fcm_notification
            
            # è¿½åŠ ãƒ‡ãƒ¼ã‚¿
            data = {
                "type": "proactive_suggestion",
                "suggestion_id": suggestion.id,
                "trigger_type": suggestion.trigger_type,
                "action_type": suggestion.action_type.value if suggestion.action_type else None,
                "action_label": suggestion.action_label,
                "news_count": str(len(new_articles)),
                "click_action": "/news"
            }
            
            # FCMé€ä¿¡
            result = send_fcm_notification(
                token=fcm_token,
                title=suggestion.title,
                body=suggestion.message,
                data=data,
                language=language
            )
            
            if result:
                if logger.isEnabledFor(logging.DEBUG):
                    pass
            else:
                logger.warning(f"âŒ FCM standard proactive notification failed")
                
        except Exception as e:
            logger.error(f"Error sending FCM standard notification: {e}")

    async def _send_fcm_proactive_notification(self, fcm_token: str, suggestion: Any, language: str, new_articles: List[CollectedNews]):
        """FCMãƒ—ãƒƒã‚·ãƒ¥é€šçŸ¥ã§ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ææ¡ˆã‚’é€ä¿¡"""
        try:
            from app.utils.fcm_sender import send_fcm_notification
            
            # é€šçŸ¥å†…å®¹ã‚’è¨€èªã«å¿œã˜ã¦ç”Ÿæˆ
            if language == "ja":
                title = "ğŸ’¡ æ–°ã—ã„é˜²ç½æƒ…å ±"
                body = suggestion.content[:100] + ("..." if len(suggestion.content) > 100 else "")
            else:
                title = "ğŸ’¡ New Disaster Prevention Info"
                body = suggestion.content[:100] + ("..." if len(suggestion.content) > 100 else "")
            
            # è¿½åŠ ãƒ‡ãƒ¼ã‚¿
            data = {
                "type": "proactive_suggestion",
                "suggestion_id": suggestion.suggestion_id,
                "suggestion_type": suggestion.type,
                "action_query": suggestion.action_query,
                "news_count": str(len(new_articles)),
                "click_action": "/suggestions"
            }
            
            # FCMé€ä¿¡
            result = send_fcm_notification(
                token=fcm_token,
                title=title,
                body=body,
                data=data,
                language=language
            )
            
            if result:
                if logger.isEnabledFor(logging.DEBUG):
                    pass
            else:
                logger.warning(f"âŒ FCM proactive notification failed")
                
        except Exception as e:
            logger.error(f"Error sending FCM proactive notification: {e}")

    def get_latest_news(self, mode: Optional[CollectionMode] = None, limit: int = 10) -> List[CollectedNews]:
        """æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—"""
        articles = list(self.collected_news.values())
        
        # ãƒ¢ãƒ¼ãƒ‰ã§ãƒ•ã‚£ãƒ«ã‚¿
        if mode:
            articles = [a for a in articles if a.mode == mode]
        
        # åé›†æ™‚åˆ»ã§ã‚½ãƒ¼ãƒˆ
        articles.sort(key=lambda x: x.collected_at, reverse=True)
        
        return articles[:limit]

    def get_collection_status(self) -> Dict[str, Any]:
        """åé›†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
        return {
            "is_running": self.is_running,
            "current_mode": self.current_mode,
            "environment": self.environment,
            "normal_config": {
                "interval_minutes": self.normal_config.interval_minutes,
                "max_articles": self.normal_config.max_articles_per_cycle,
                "keywords_count": len(self.normal_config.search_keywords)
            },
            "emergency_config": {
                "interval_minutes": self.emergency_config.interval_minutes,
                "max_articles": self.emergency_config.max_articles_per_cycle,
                "keywords_count": len(self.emergency_config.search_keywords),
                "target_location": {
                    "latitude": self.emergency_config.target_location.latitude,
                    "longitude": self.emergency_config.target_location.longitude
                } if self.emergency_config.target_location else None
            },
            "emergency_locations_count": len(self.emergency_locations),
            "cached_articles_count": len(self.collected_news),
            "articles_by_mode": {
                "normal": len([a for a in self.collected_news.values() if a.mode == CollectionMode.NORMAL]),
                "emergency": len([a for a in self.collected_news.values() if a.mode == CollectionMode.EMERGENCY])
            }
        }

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
adaptive_news_collector = AdaptiveNewsCollector()

# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
async def start_adaptive_news_collection():
    """é©å¿œçš„ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚’é–‹å§‹"""
    await adaptive_news_collector.start_collection()

async def stop_adaptive_news_collection():
    """é©å¿œçš„ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚’åœæ­¢"""
    await adaptive_news_collector.stop_collection()

def add_emergency_location(location: Location):
    """ç·Šæ€¥ç›£è¦–ä½ç½®ã‚’è¿½åŠ """
    return adaptive_news_collector.add_emergency_location(location)

def remove_emergency_location(location: Location):
    """ç·Šæ€¥ç›£è¦–ä½ç½®ã‚’å‰Šé™¤"""
    return adaptive_news_collector.remove_emergency_location(location)

def get_latest_news(mode: Optional[CollectionMode] = None, limit: int = 10) -> List[CollectedNews]:
    """æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—"""
    return adaptive_news_collector.get_latest_news(mode, limit)