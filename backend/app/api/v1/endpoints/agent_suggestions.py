# app/api/v1/endpoints/agent_suggestions.py (æ–°è¦ä½œæˆä¾‹)
from fastapi import APIRouter, Depends, HTTPException, status, Request
# from pydantic import BaseModel, Field # ãƒ­ãƒ¼ã‚«ãƒ«å®šç¾©ã‚’å‰Šé™¤ã™ã‚‹ãŸã‚ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
from typing import List, Dict, Any, Optional # List, Dict, Any, Optional ã¯ã‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ã‚«ãƒãƒ¼ã•ã‚Œã‚‹ã‹ç¢ºèª
import logging
# Depends, HTTPException ã¯POSTã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# from fastapi import Depends, HTTPException # é‡è¤‡ã‚¤ãƒ³ãƒãƒ¼ãƒˆãªã®ã§å‰Šé™¤
# from pydantic import BaseModel, Field # ãƒ­ãƒ¼ã‚«ãƒ«å®šç¾©ã‚’å‰Šé™¤ã™ã‚‹ãŸã‚ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from app.agents.safety_beacon_agent.proactive_suggester import invoke_proactive_agent
# æ­£ã—ã„ã‚¹ã‚­ãƒ¼ãƒã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from app.schemas.agent.suggestions import ProactiveSuggestionContext, SuggestionItem, ProactiveSuggestionResponse
from app.schemas.unified_event import UnifiedEventData # UnifiedEventData ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from app.services.event_filter_service import filter_events_by_location # ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–¢æ•°
from app.db.firestore_client import get_db # Firestoreã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
from google.cloud.firestore_v1 import FieldFilter
from datetime import datetime, timedelta, timezone # æ—¥æ™‚æ“ä½œ
from app.services.device_service import get_device_by_id
# Removed unused user_crud import
from app.tools.jma_poller_tool import get_current_disaster_context

logger = logging.getLogger(__name__)
router = APIRouter()

async def classify_suggestions_with_llm(suggestions: List[SuggestionItem], language_code: str) -> Optional[Dict[str, Any]]:
    """
    LLMã‚’ä½¿ç”¨ã—ã¦ææ¡ˆãƒªã‚¹ãƒˆã‚’è‡ªç„¶è¨€èªã§åˆ†é¡ã—ã€ç½å®³é–¢é€£åº¦ã¨æ·±åˆ»åº¦ã‚’åˆ¤å®š
    """
    try:
        from app.agents.safety_beacon_agent.core.llm_singleton import get_llm_client
        
        llm = get_llm_client()
        
        # ææ¡ˆå†…å®¹ã‚’ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æ•´ç†
        suggestions_text = []
        for i, suggestion in enumerate(suggestions, 1):
            suggestion_info = f"{i}. Type: {suggestion.type}\n   Content: {suggestion.content}"
            if suggestion.action_query:
                suggestion_info += f"\n   Action: {suggestion.action_query}"
            suggestions_text.append(suggestion_info)
        
        suggestions_summary = "\n\n".join(suggestions_text)
        
        prompt = f"""You are analyzing proactive suggestions from a disaster safety app to classify their disaster-relatedness and severity.

Language for analysis: {language_code}

Suggestions to analyze:
{suggestions_summary}

Your task:
1. Analyze ALL suggestions as a group and determine if ANY of them are disaster-related
2. If disaster-related, assess the HIGHEST severity level among all suggestions
3. Extract any disaster event IDs mentioned in ANY of the suggestions

Classification criteria:
- Disaster-related: Suggestions about emergency response, disaster preparation, evacuation, safety alerts, emergency contacts, shelter information, disaster news, etc.
- Non disaster-related: General app features, welcome messages, settings, unrelated recommendations

Severity levels (in order of urgency):
- "ç·Šæ€¥" (Critical): Immediate danger, active disaster, emergency evacuation
- "é«˜ã„" (High): Warning alerts, disaster preparation during alert
- "ä¸­ç¨‹åº¦" (Medium): General disaster preparation, safety reminders
- "ä½ã„" (Low): Educational content, routine safety tips

Return a SINGLE JSON object that represents the OVERALL classification of ALL suggestions combined:
{{
    "is_disaster_related": boolean,
    "disaster_severity": "ç·Šæ€¥|é«˜ã„|ä¸­ç¨‹åº¦|ä½ã„" or null,
    "disaster_event_ids": [list of event IDs found],
    "reasoning": "brief explanation of classification"
}}

IMPORTANT: 
- Return ONE JSON object, NOT an array
- Do not analyze suggestions individually
- Do not include any text before or after the JSON
- Return ONLY the JSON object"""

        response = await llm.ainvoke(prompt)
        
        # ãƒ‡ãƒãƒƒã‚°: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‹ã¨å†…å®¹ã‚’ãƒ­ã‚°å‡ºåŠ›
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‹ã‚’ç¢ºèªã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        if hasattr(response, 'content'):
            response_text = response.content
        elif isinstance(response, list) and len(response) > 0:
            # ãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆã€æœ€åˆã®è¦ç´ ã‚’ä½¿ç”¨
            first_item = response[0]
            if hasattr(first_item, 'content'):
                response_text = first_item.content
            else:
                response_text = str(first_item)
        else:
            response_text = str(response)
            
        # JSONã‚’ãƒ‘ãƒ¼ã‚¹
        import json
        cleaned_response = response_text.strip()
        # Remove code block markers if present
        if cleaned_response.startswith("```json"):
            cleaned_response = cleaned_response[7:]
        elif cleaned_response.startswith("```"):
            cleaned_response = cleaned_response[3:]
        if cleaned_response.endswith("```"):
            cleaned_response = cleaned_response[:-3]
        cleaned_response = cleaned_response.strip()
        
        # Extract JSON if there's extra text
        import re
        json_match = re.search(r'\{[^{}]*\}', cleaned_response, re.DOTALL)
        if json_match:
            cleaned_response = json_match.group(0)
        
        classification = json.loads(cleaned_response)
        
        # åˆ†é¡çµæœã®å‹ãƒã‚§ãƒƒã‚¯
        if isinstance(classification, dict):
            logger.info(f"LLM suggestion classification: {classification.get('reasoning', 'No reasoning provided')}")
            return classification
        else:
            logger.warning(f"Unexpected classification format: {type(classification)}")
            return None
        
    except Exception as e:
        logger.error(f"Failed to classify suggestions with LLM: {e}")
        return None

# Pydanticãƒ¢ãƒ‡ãƒ«å®šç¾©ã¯ schemas ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚å‰Šé™¤

# --- â˜… ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ) ---
# @router.get("/api/v1/agent/health", status_code=status.HTTP_200_OK, tags=["Agent Health"])
# async def agent_health_check():
#     """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
#     logger.info("Agent suggestions router health check endpoint hit.")
#     return {"status": "OK", "message": "Agent suggestions router is active"}
# ---------------------------------------------

# --- POSTã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (invoke_proactive_agentå‘¼ã³å‡ºã—ã‚’æœ‰åŠ¹åŒ–) ---
@router.post(
    "/agent/proactive-suggestions", # ç›¸å¯¾ãƒ‘ã‚¹ã«æˆ»ã™
    response_model=ProactiveSuggestionResponse,
    summary="Get proactive suggestions based on current context (Deprecated - Use /sync/heartbeat instead)",
    tags=["Agent"],
    deprecated=True
)
async def get_proactive_suggestions(
    context: ProactiveSuggestionContext,
    request: Request,
):
    return await _handle_proactive_suggestions(context, request)

# ãƒ¬ã‚¬ã‚·ãƒ¼äº’æ›æ€§ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯å‰Šé™¤æ¸ˆã¿
# ä½¿ç”¨ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: POST /api/v1/sync/heartbeat

# å…±é€šå‡¦ç†é–¢æ•°
async def _handle_proactive_suggestions(
    context: ProactiveSuggestionContext,
    request: Request,
):
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
    client_ip = request.client.host if request.client else "unknown"
    logger.info(f"API Request from IP: {client_ip}")
    log_message_device_id = f"Received proactive suggestion request for device: {context.device_id}"
    logger.critical(f"--- CRITICAL LOG: Device ID: {context.device_id} ---") # CRITICALãƒ¬ãƒ™ãƒ«ã§ç›®ç«‹ãŸã›ã‚‹
    logger.info(f"Request received at: {datetime.now(timezone.utc).isoformat()}")

    # current_situation ã®å€¤ã‚’æ˜ç¢ºã«ãƒ­ã‚°å‡ºåŠ›
    log_message_situation = f"Received current_situation: {context.current_situation}"
    logger.critical(f"--- CRITICAL LOG: {log_message_situation} ---")
    # is_emergency_mode ã®å€¤ã‚’ãƒ­ã‚°å‡ºåŠ›
    log_message_emergency = f"Received is_emergency_mode: {context.is_emergency_mode}"
    logger.critical(f"--- CRITICAL LOG: Emergency Mode: {context.is_emergency_mode} ---")
    if context.latest_alert_summary:
        alert_summary_json = context.latest_alert_summary.model_dump_json(indent=2)
        log_message_alert = f"Received latest_alert_summary (type: {type(context.latest_alert_summary)}): {alert_summary_json}"
        logger.critical(f"--- CRITICAL LOG: Latest Alert Summary: {alert_summary_json} ---")
    else:
        log_message_alert_none = "Received latest_alert_summary is None."
        logger.critical(f"--- CRITICAL LOG: {log_message_alert_none} ---")
    full_context_json = context.model_dump_json(indent=2)
    log_message_full_context = f"Full ProactiveSuggestionContext: {full_context_json}"
    logger.info(f"--- INFO LOG: Full Context: {full_context_json} ---") # INFOãƒ¬ãƒ™ãƒ«ã«æˆ»ã™ï¼ˆCRITICALã¯å¤šç”¨ã—ãªã„ï¼‰
    # --- Firestoreã‹ã‚‰æ­£è¦åŒ–æ¸ˆã¿ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—ã—ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ  ---
    try:
        db = get_db()
        # unified_disaster_events ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ç›´è¿‘ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾— (ä¾‹: éå»24æ™‚é–“)
        # ã“ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã¯ event_normalizer.py ã§ã®ä¿å­˜å…ˆã¨åˆã‚ã›ã‚‹
        events_ref = db.collection("unified_disaster_events")

        # Firestoreã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ¯”è¼ƒã®ãŸã‚ã«ã€datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æº–å‚™
        # ã“ã“ã§ã¯ä¾‹ã¨ã—ã¦éå»24æ™‚é–“ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—
        time_threshold = datetime.now(timezone.utc) - timedelta(hours=24)

        # 'fetched_at' ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§é™é †ã‚½ãƒ¼ãƒˆã—ã€æ–°ã—ã„ã‚‚ã®ã‹ã‚‰å–å¾—ã€ãã®å¾Œæ™‚é–“ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        # query = events_ref.order_by("fetched_at", direction="DESCENDING").where("fetched_at", ">=", time_threshold).limit(50) # ä¾‹: æœ€å¤§50ä»¶
        # Firestoreã®whereå¥ã¯ >= ã¨ orderBy ã®çµ„ã¿åˆã‚ã›ã«æ³¨æ„ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚‹ã€‚
        # fetched_at ã¯ISOæ–‡å­—åˆ—ã§ä¿å­˜ã•ã‚Œã¦ã„ã‚‹æƒ³å®šãªã®ã§ã€æ–‡å­—åˆ—æ¯”è¼ƒã«ãªã‚‹ã€‚
        # ã‚ˆã‚Šå …ç‰¢ãªã®ã¯ã€Firestoreã®Timestampå‹ã§ä¿å­˜ã™ã‚‹ã“ã¨ã€‚
        # ä»Šå›ã¯ event_normalizer.py ã§ISOæ–‡å­—åˆ—ã§ä¿å­˜ã™ã‚‹æƒ³å®šãªã®ã§ã€æ–‡å­—åˆ—ã§æ¯”è¼ƒã€‚
        query = events_ref.where(filter=FieldFilter("fetched_at", ">=", time_threshold.isoformat())).limit(50) # limitã¯é©å®œèª¿æ•´

        # query.stream() ã¯åŒæœŸã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã®ãŸã‚ async for ã§ç›´æ¥ä½¿ãˆãªã„
        # query.get() ã¯åŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã®ãŸã‚ã€asyncio.to_thread ã‚’ä½¿ã£ã¦éåŒæœŸã«å®Ÿè¡Œã™ã‚‹
        import asyncio # asyncio ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        docs_snapshot = await asyncio.to_thread(query.get)

        all_recent_unified_events: List[UnifiedEventData] = []
        for doc in docs_snapshot: # å–å¾—ã—ãŸã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ãƒ«ãƒ¼ãƒ—å‡¦ç†
            try:
                event_dict = doc.to_dict()
                # Firestoreã‹ã‚‰èª­ã¿è¾¼ã‚“ã reported_at, fetched_atã¯æ–‡å­—åˆ—ãªã®ã§datetimeã«å¤‰æ›
                if event_dict.get("reported_at"):
                    event_dict["reported_at"] = datetime.fromisoformat(event_dict["reported_at"])
                if event_dict.get("fetched_at"):
                    event_dict["fetched_at"] = datetime.fromisoformat(event_dict["fetched_at"])
                all_recent_unified_events.append(UnifiedEventData(**event_dict))
            except Exception as parse_e:
                logger.error(f"Error parsing UnifiedEventData from Firestore doc {doc.id}: {parse_e}", exc_info=True)

        logger.info(f"Fetched {len(all_recent_unified_events)} recent unified events from Firestore.")

        if context.current_location:
            # current_area_codes ãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã§æä¾›ã•ã‚Œã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ç”¨
            # ãªã‘ã‚Œã°ã€current_location ã‹ã‚‰é€†ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§å–å¾—ã™ã‚‹å‡¦ç†ãŒå¿…è¦ (ä»Šå›ã¯çœç•¥ã—ã€Noneã®ã¾ã¾)
            target_codes = context.current_area_codes

            filtered_events = filter_events_by_location(
                events=all_recent_unified_events,
                current_location=context.current_location,
                target_area_codes=target_codes
                # radius_km ã¯ event_filter.py ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
            )
            context.recent_normalized_events = filtered_events
            logger.info(f"Filtered down to {len(filtered_events)} relevant events for context.")
        else:
            # ç¾åœ¨åœ°ãŒãªã„å ´åˆã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã›ãšã€å–å¾—ã—ãŸã‚¤ãƒ™ãƒ³ãƒˆã‚’ãã®ã¾ã¾åˆ©ç”¨ (ã¾ãŸã¯ç©ºã«ã™ã‚‹)
            # ã“ã“ã§ã¯ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãªã—ã§å…¨ä»¶æ¸¡ã™ã‹ã€ã‚ã‚‹ã„ã¯ææ¡ˆã®è³ªã‚’è€ƒæ…®ã—ã¦æ¸¡ã•ãªã„ã‹æ¤œè¨
            # ä»Šå›ã¯ã€ç¾åœ¨åœ°ãŒãªã„å ´åˆã¯ normalized_events ã¯ None ã®ã¾ã¾ã«ã™ã‚‹
            logger.warning("Current location not provided in context, skipping event filtering for recent_normalized_events.")
            context.recent_normalized_events = None # ã¾ãŸã¯ all_recent_unified_events ã‚’ãã®ã¾ã¾å…¥ã‚Œã‚‹ã‹

    except Exception as db_e:
        logger.error(f"Error fetching or filtering unified events from Firestore: {db_e}", exc_info=True)
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ã€recent_normalized_events ã¯ None ã®ã¾ã¾å‡¦ç†ã‚’ç¶šè¡Œ
        context.recent_normalized_events = None
    # --- ã“ã“ã¾ã§ã‚¤ãƒ™ãƒ³ãƒˆå–å¾—ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç† ---

    # --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å–å¾—ã—ã¦è¨€èªæ¤œå‡ºç”¨ã«è¨­å®š ---
    try:
        if not context.suggestion_history_summary:
            # Firestoreã‹ã‚‰ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å–å¾—
            db = get_db()
            chat_history_ref = db.collection("chat_sessions").where(filter=FieldFilter("device_id", "==", context.device_id))
            
            # æœ€æ–°ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å–å¾—ï¼ˆæœ€å¤§10ä»¶ï¼‰
            import asyncio
            chat_docs = await asyncio.to_thread(chat_history_ref.order_by("created_at", direction="DESCENDING").limit(10).get)
            
            recent_user_inputs = []
            for doc in chat_docs:
                try:
                    chat_data = doc.to_dict()
                    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’æŠ½å‡º
                    if chat_data.get("messages"):
                        for msg in reversed(chat_data["messages"]):  # æœ€æ–°ã‹ã‚‰æ¤œç´¢
                            if msg.get("role") == "human" and msg.get("content"):
                                recent_user_inputs.append(msg["content"])
                                if len(recent_user_inputs) >= 3:  # æœ€æ–°3ä»¶ã§ååˆ†
                                    break
                        if len(recent_user_inputs) >= 3:
                            break
                except Exception as parse_e:
                    logger.error(f"Error parsing chat history from doc {doc.id}: {parse_e}")
            
            if recent_user_inputs:
                # ç–‘ä¼¼çš„ãªsuggestion_history_summaryã‚’ä½œæˆ
                from types import SimpleNamespace
                fake_history = []
                for user_input in recent_user_inputs:
                    fake_history.append(SimpleNamespace(content=user_input, user_input=user_input))
                context.suggestion_history_summary = fake_history
                logger.info(f"Retrieved {len(recent_user_inputs)} recent user inputs from chat history for language detection")
            else:
                logger.info("No recent chat history found for language detection")
    
    except Exception as history_e:
        logger.error(f"Error retrieving chat history for language detection: {history_e}")
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ææ¡ˆå‡¦ç†ã¯ç¶šè¡Œ
    # --- ã“ã“ã¾ã§ãƒãƒ£ãƒƒãƒˆå±¥æ­´å–å¾—å‡¦ç† ---

    try:
        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†: limitãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯é©ç”¨
        if context.limit:
            logger.info(f"Applying limit parameter: {context.limit}")

        # å·®åˆ†æ›´æ–°å‡¦ç†: last_suggestion_timestampãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯é©ç”¨
        if context.last_suggestion_timestamp:
            logger.info(f"Filtering suggestions newer than: {context.last_suggestion_timestamp}")

        # æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ãƒã‚§ãƒƒã‚¯
        from app.services.adaptive_news_collector import adaptive_news_collector
        new_news_info = adaptive_news_collector.get_new_news_info()
        
        # invoke_proactive_agent ã‚’å‘¼ã³å‡ºã—ã€çµæœã‚’å–å¾— (List[SuggestionItem])
        suggestions_list_items = await invoke_proactive_agent(context)
        
        # æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚‹å ´åˆã€ãƒ‹ãƒ¥ãƒ¼ã‚¹é–¢é€£ã®ææ¡ˆã‚’è¿½åŠ 
        if new_news_info and context.current_situation == "normal":
            await _add_news_based_suggestions(suggestions_list_items, new_news_info, context)

        # ææ¡ˆå±¥æ­´ã®å‡¦ç†ã‚’å¼·åŒ–
        if context.suggestion_history_summary:
            logger.info(f"Processing suggestion history with {len(context.suggestion_history_summary)} items")

        # LLMã‚’ä½¿ç”¨ã—ãŸè‡ªç„¶è¨€èªåˆ†é¡ã§ç½å®³é–¢é€£ææ¡ˆã‚’è­˜åˆ¥
        is_disaster_related = False
        disaster_severity = None
        disaster_event_ids = set()

        # 1. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ç½å®³ã‚¤ãƒ™ãƒ³ãƒˆãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if context.recent_normalized_events:
            is_disaster_related = True
            disaster_event_ids.update(e.event_id for e in context.recent_normalized_events if e.event_id)

            # æ·±åˆ»åº¦è¨ˆç®—: ã‚¤ãƒ™ãƒ³ãƒˆã®æ·±åˆ»åº¦ã‚’è€ƒæ…®
            event_severities = []
            for event in context.recent_normalized_events:
                if hasattr(event, 'severity_level'):
                    event_severities.append(event.severity_level)
                if hasattr(event, 'action_data') and event.action_data and 'severity' in event.action_data:
                    event_severities.append(event.action_data['severity'])

            if event_severities:
                severity_order = ["ç·Šæ€¥", "é«˜ã„", "ä¸­ç¨‹åº¦", "ä½ã„"]
                disaster_severity = min(
                    event_severities,
                    key=lambda x: severity_order.index(x) if x in severity_order else len(severity_order)
                )

        # 2. LLMã«ã‚ˆã‚‹è‡ªç„¶è¨€èªåˆ†é¡ã§ç½å®³é–¢é€£ææ¡ˆã‚’ãƒã‚§ãƒƒã‚¯
        if suggestions_list_items:
            disaster_classification = await classify_suggestions_with_llm(suggestions_list_items, context.language_code)
            
            if disaster_classification:
                is_disaster_related = disaster_classification.get("is_disaster_related", False)
                llm_severity = disaster_classification.get("disaster_severity")
                llm_event_ids = disaster_classification.get("disaster_event_ids", [])
                
                # LLMã‹ã‚‰å–å¾—ã—ãŸæƒ…å ±ã‚’ãƒãƒ¼ã‚¸
                if llm_severity:
                    severity_order = ["ç·Šæ€¥", "é«˜ã„", "ä¸­ç¨‹åº¦", "ä½ã„"]
                    if disaster_severity is None or (llm_severity in severity_order and 
                        (disaster_severity not in severity_order or 
                         severity_order.index(llm_severity) < severity_order.index(disaster_severity))):
                        disaster_severity = llm_severity
                
                disaster_event_ids.update(llm_event_ids)

        # setã‚’listã«å¤‰æ›
        disaster_event_ids = list(disaster_event_ids)

        # Calculate next check time based on context
        next_check_minutes = 60  # Default
        if suggestions_list_items:
            # In disaster mode, check more frequently
            if context.current_situation == "alert_active":
                next_check_minutes = 15
            else:
                next_check_minutes = 30
        
        next_check_after = datetime.now(timezone.utc).replace(second=0, microsecond=0)
        next_check_after = next_check_after.replace(
            minute=(next_check_after.minute + next_check_minutes) % 60
        )
        if (next_check_after.minute < datetime.now(timezone.utc).minute):
            next_check_after = next_check_after + timedelta(hours=1)
        
        # ProactiveSuggestionResponseå½¢å¼ã§è¿”ã™
        response = {
            "suggestions": suggestions_list_items,
            "is_disaster_related": is_disaster_related,
            "disaster_severity": disaster_severity,
            "disaster_event_ids": disaster_event_ids,
            "has_more_items": False,  # åˆæœŸå€¤ã¯Falseã€å®Ÿéš›ã®å€¤ã¯invoke_proactive_agentã§è¨­å®š
            "next_check_after": next_check_after
        }

        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        logger.info(f"Returning {len(response['suggestions'])} suggestions (has_more_items: {response['has_more_items']})")
        return response
    except Exception as e:
        logger.error(f"Error generating proactive suggestions: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Failed to generate suggestions")
# ---------------------------------------------------------

# --- ãƒ‡ãƒã‚¤ã‚¹å˜ä½ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯çµ±åˆãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆAPIã§ç½®ãæ›ãˆ ---
# å‰Šé™¤æ¸ˆã¿: /agent/proactive-suggestions/device/{device_id}
# æ–°ã—ã„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨: POST /api/v1/sync/heartbeat

# --- ææ¡ˆæ‰¿èªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯çµ±åˆãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆAPIã§ç½®ãæ›ãˆ ---
# å‰Šé™¤æ¸ˆã¿: POST /agent/proactive-suggestions/{suggestion_id}/acknowledge
# ç†ç”±: ææ¡ˆæ‰¿èªã¯ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆAPIã®client_context.acknowledged_suggestionsã§ç®¡ç†
# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã¯æ‰¿èªæ¸ˆã¿IDã‚’ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆé€ä¿¡æ™‚ã«å«ã‚ã‚‹ã“ã¨ã§åŒã˜æ©Ÿèƒ½ã‚’å®Ÿç¾

async def _add_news_based_suggestions(suggestions_list: List, new_news_info: Dict[str, Any], context):
        """æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«åŸºã¥ãææ¡ˆã‚’è¿½åŠ """
        try:
            from app.schemas.agent.suggestions import SuggestionItem
            from datetime import datetime
            import uuid
            
            new_articles_count = new_news_info.get("new_articles_count", 0)
            latest_articles = new_news_info.get("latest_articles", [])
            
            if new_articles_count > 0 and latest_articles:
                # ãƒ‹ãƒ¥ãƒ¼ã‚¹é–¢é€£ã®ææ¡ˆã‚’ç”Ÿæˆ
                # LLMã§ã‚¢ãƒ—ãƒªæŒ‡å®šè¨€èªã®ç½å®³ãƒ‹ãƒ¥ãƒ¼ã‚¹ææ¡ˆã‚’ç”Ÿæˆ
                from app.services.proactive_suggester import generate_disaster_news_content_with_llm
                
                news_content_llm = await generate_disaster_news_content_with_llm(
                    context.language_code, new_articles_count, latest_articles
                )
                
                news_suggestion = SuggestionItem(
                    type="disaster_news",
                    content=news_content_llm["content"],
                    action_data={
                        "news_articles_count": new_articles_count,
                        "latest_update": new_news_info.get("last_update_time"),
                        "news_trigger": True
                    },
                    suggestion_id=str(uuid.uuid4()),
                    action_query=news_content_llm["action_query"],
                    action_display_text=news_content_llm["action_display_text"],
                    created_at=datetime.now()
                )
                
                # ãƒªã‚¹ãƒˆã®å…ˆé ­ã«è¿½åŠ ï¼ˆå„ªå…ˆè¡¨ç¤ºï¼‰
                suggestions_list.insert(0, news_suggestion)
                logger.info(f"ğŸ’¡ Added news-based suggestion: {new_articles_count} new articles")
                
        except Exception as e:
            logger.error(f"Error adding news-based suggestions: {e}")
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚æ—¢å­˜ã®ææ¡ˆã¯ç¶­æŒ
