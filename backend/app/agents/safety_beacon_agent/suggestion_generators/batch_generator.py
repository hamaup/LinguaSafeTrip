#!/usr/bin/env python3
"""
Batch Suggestion Generator - LLM Optimization
ãƒãƒƒãƒææ¡ˆç”Ÿæˆå™¨ - LLMåŠ¹ç‡åŒ–
"""

import logging
import json
from typing import List, Dict, Any, Optional
from app.schemas.agent.suggestions import SuggestionItem
from app.schemas.agent.suggestions import ProactiveSuggestionContext
from app.agents.safety_beacon_agent.core.llm_singleton import ainvoke_llm
from app.prompts.suggestion_prompts import BATCH_SUGGESTION_GENERATION_PROMPT

logger = logging.getLogger(__name__)

class BatchSuggestionGenerator:
    """ãƒãƒƒãƒææ¡ˆç”Ÿæˆå™¨ - è¤‡æ•°ã®ææ¡ˆã‚’1å›ã®LLMå‘¼ã³å‡ºã—ã§ç”Ÿæˆ"""
    
    def __init__(self):
        self.suggestion_types = {
            "welcome_message": "Welcome greeting for new users",  # å¹³å¸¸æ™‚ã®ã¿
            "emergency_contact_setup": "Reminder to set up emergency contacts",
            "seasonal_warning": "Warning about seasonal disasters and preparation",  # å¹³å¸¸æ™‚ã®ã¿
            "low_battery_warning": "Reminder to charge phone for emergency readiness",
            "quiz_reminder": "Interactive disaster preparedness quiz",
            "disaster_news": "Recent disaster news relevant to user location",
            "disaster_preparedness": "Disaster preparedness tips and prevention information",
            "hazard_map_url": "Local hazard maps and emergency information",
            "shelter_status_update": "Nearby evacuation shelter status",
            "immediate_safety_action": "Immediate safety actions for current situation",
            "location_permission_reminder": "Request location permission for better assistance",
            "notification_permission_reminder": "Request notification permission for alerts",
            "safety_confirmation_sms_proposal": "Propose sending safety confirmation SMS"  # ç·Šæ€¥æ™‚ã®ã¿
        }
    
    async def generate_batch_suggestions(
        self,
        suggestion_types: List[str],
        context: ProactiveSuggestionContext,
        language_code: str = "ja"
    ) -> Dict[str, Optional[SuggestionItem]]:
        """
        è¤‡æ•°ã®ææ¡ˆã‚’1å›ã®LLMå‘¼ã³å‡ºã—ã§ç”Ÿæˆï¼ˆåŠ¹ç‡åŒ–ï¼‰
        
        Args:
            suggestion_types: ç”Ÿæˆã™ã‚‹ææ¡ˆã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆ
            context: ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ææ¡ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            language_code: å‡ºåŠ›è¨€èªï¼ˆç¿»è¨³ã¯å¾Œã§å®Ÿè¡Œï¼‰
            
        Returns:
            ææ¡ˆã‚¿ã‚¤ãƒ—ã‚’ã‚­ãƒ¼ã¨ã—ãŸææ¡ˆã‚¢ã‚¤ãƒ†ãƒ è¾æ›¸
        """
        try:
            # ãƒãƒƒãƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            batch_prompt = self._build_batch_prompt(suggestion_types, context, language_code)
            
            # 1å›ã®LLMå‘¼ã³å‡ºã—ã§å…¨ã¦ã®ææ¡ˆã‚’ç”Ÿæˆ
            response = await ainvoke_llm(
                prompt=batch_prompt,
                task_type="response_generation",
                temperature=0.7,
                max_tokens=2048
            )
            
            # å¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦å€‹åˆ¥ã®ææ¡ˆã«åˆ†å‰²
            suggestions = await self._parse_batch_response(response, suggestion_types, context, language_code)
            
            return suggestions
            
        except Exception as e:
            logger.error(f"Batch suggestion generation failed: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç©ºã®çµæœã‚’è¿”ã™
            return {suggestion_type: None for suggestion_type in suggestion_types}
    
    def _build_batch_prompt(
        self,
        suggestion_types: List[str],
        context: ProactiveSuggestionContext,
        language_code: str
    ) -> str:
        """ãƒãƒƒãƒç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’æ•´ç†
        context_info = self._format_context_info(context)
        
        # å„ææ¡ˆã‚¿ã‚¤ãƒ—ã®èª¬æ˜ã‚’æº–å‚™
        type_descriptions = []
        for i, suggestion_type in enumerate(suggestion_types, 1):
            description = self.suggestion_types.get(suggestion_type, f"Generate {suggestion_type}")
            type_descriptions.append(f"{i}. {suggestion_type}: {description}")
        
        prompt = BATCH_SUGGESTION_GENERATION_PROMPT.format(
            context_info=context_info,
            type_descriptions=chr(10).join(type_descriptions),
            suggestion_count=len(suggestion_types)
        )
        
        return prompt
    
    def _format_context_info(self, context: ProactiveSuggestionContext) -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        info_parts = []
        
        # ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰æƒ…å ±
        emergency_mode = False
        if hasattr(context, 'emergency_mode') and context.emergency_mode:
            emergency_mode = True
            info_parts.append("âš ï¸ EMERGENCY MODE ACTIVE")
        
        # ç½å®³ã‚¢ãƒ©ãƒ¼ãƒˆæƒ…å ±
        if hasattr(context, 'disaster_alerts') and context.disaster_alerts:
            alert_count = len(context.disaster_alerts)
            info_parts.append(f"ğŸš¨ {alert_count} active disaster alert(s)")
        
        # ç·Šæ€¥æ™‚ã®åˆ¶é™æƒ…å ±ã‚’è¿½åŠ 
        if emergency_mode:
            info_parts.append("ğŸš« EMERGENCY RESTRICTIONS: welcome_message and seasonal_warning are disabled")
        
        # æ™‚åˆ»æƒ…å ±
        if hasattr(context, 'current_time'):
            info_parts.append(f"Time: {context.current_time}")
        
        # ä½ç½®æƒ…å ±
        if hasattr(context, 'location') and context.location:
            info_parts.append(f"Location: {context.location}")
        
        # ã‚¢ãƒ—ãƒªä½¿ç”¨çŠ¶æ³
        if hasattr(context, 'user_app_usage_summary') and context.user_app_usage_summary:
            usage = context.user_app_usage_summary
            if hasattr(usage, 'local_contact_count'):
                info_parts.append(f"Emergency contacts: {usage.local_contact_count}")
            if hasattr(usage, 'last_active_days'):
                info_parts.append(f"Last active: {usage.last_active_days} days ago")
        
        return "\n".join(info_parts) if info_parts else "No specific context available"
    
    async def _parse_batch_response(
        self,
        response: str,
        expected_types: List[str],
        context: ProactiveSuggestionContext,
        language_code: str
    ) -> Dict[str, Optional[SuggestionItem]]:
        """ãƒãƒƒãƒå¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦å€‹åˆ¥ã®ææ¡ˆã«åˆ†å‰²"""
        try:
            # JSONã‚’æŠ½å‡º
            json_match = self._extract_json_from_response(response)
            if not json_match:
                logger.error("No valid JSON found in batch response")
                return {suggestion_type: None for suggestion_type in expected_types}
            
            data = json.loads(json_match)
            suggestions_data = data.get('suggestions', [])
            
            # ææ¡ˆè¾æ›¸ã‚’æ§‹ç¯‰
            suggestions = {}
            
            for suggestion_data in suggestions_data:
                suggestion_type = suggestion_data.get('type')
                if suggestion_type in expected_types:
                    try:
                        suggestion_item = SuggestionItem(
                            type=suggestion_type,
                            content=suggestion_data.get('content', ''),
                            action_query=suggestion_data.get('action_query', ''),
                            action_display_text=suggestion_data.get('action_display_text', ''),
                            action_data=suggestion_data.get('action_data', {})
                        )
                        suggestions[suggestion_type] = suggestion_item
                    except Exception as e:
                        logger.error(f"Failed to create SuggestionItem for {suggestion_type}: {e}")
                        suggestions[suggestion_type] = None
                else:
                    logger.warning(f"Unexpected suggestion type in response: {suggestion_type}")
            
            # ä¸è¶³ã—ã¦ã„ã‚‹ææ¡ˆã‚¿ã‚¤ãƒ—ã‚’å€‹åˆ¥ç”Ÿæˆã§è£œå®Œ
            for suggestion_type in expected_types:
                if suggestion_type not in suggestions or suggestions[suggestion_type] is None:
                    logger.warning(f"Missing suggestion for type: {suggestion_type}, attempting individual generation")
                    try:
                        fallback_suggestion = await self._generate_individual_fallback(
                            suggestion_type, context, language_code
                        )
                        suggestions[suggestion_type] = fallback_suggestion
                    except Exception as e:
                        logger.error(f"Individual fallback failed for {suggestion_type}: {e}")
                        suggestions[suggestion_type] = None
            
            return suggestions
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error in batch response: {e}")
            return {suggestion_type: None for suggestion_type in expected_types}
        except Exception as e:
            logger.error(f"Error parsing batch response: {e}")
            return {suggestion_type: None for suggestion_type in expected_types}
    
    def _extract_json_from_response(self, response: str) -> Optional[str]:
        """å¿œç­”ã‹ã‚‰JSONã‚’æŠ½å‡º"""
        import re
        
        # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¢ã™
        json_patterns = [
            r'```json\s*(\{.*?\})\s*```',  # Markdownã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯
            r'```\s*(\{.*?\})\s*```',      # æ±ç”¨ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯
            r'(\{[^{}]*\{[^{}]*\}[^{}]*\})',  # ãƒã‚¹ãƒˆã—ãŸJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            r'(\{.*?\})'                   # ã‚·ãƒ³ãƒ—ãƒ«ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        ]
        
        for pattern in json_patterns:
            match = re.search(pattern, response, re.DOTALL)
            if match:
                return match.group(1)
        
        return None
    
    async def _generate_individual_fallback(
        self, 
        suggestion_type: str, 
        context: ProactiveSuggestionContext, 
        language_code: str
    ) -> Optional[SuggestionItem]:
        """å€‹åˆ¥ææ¡ˆã®ç”Ÿæˆï¼ˆãƒãƒƒãƒå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        try:
            # basic_generatorã‹ã‚‰å€‹åˆ¥ç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
            from .basic_generators import basic_generator
            
            if suggestion_type == "safety_confirmation_sms_proposal":
                return await basic_generator.generate_safety_confirmation_sms_proposal(context, language_code)
            elif suggestion_type == "seasonal_warning":
                return await basic_generator.generate_seasonal_warning(context, language_code)
            elif suggestion_type == "welcome_message":
                return await basic_generator.generate_welcome_message(context, language_code)
            # ä»–ã®å€‹åˆ¥ç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰ã‚‚å¿…è¦ã«å¿œã˜ã¦è¿½åŠ 
            else:
                logger.warning(f"No individual fallback available for {suggestion_type}")
                return None
                
        except Exception as e:
            logger.error(f"Individual fallback generation failed for {suggestion_type}: {e}")
            return None

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
batch_generator = BatchSuggestionGenerator()